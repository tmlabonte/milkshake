accelerator: gpu
batch_size: 128
check_val_every_n_epoch: 10
ckpt_every_n_epoch: 100
datamodule: cifar10
devices: 1
lr: 1e-4
lr_scheduler: cosine_warmup
lr_warmup_epochs: 5
max_epochs: 100
model: swin_transformer
optimizer: adamw
val_split: 0.1
weight_decay: 5e-4
